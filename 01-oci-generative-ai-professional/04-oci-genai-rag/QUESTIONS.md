# Skill Check - OCI GenAI Service

1. What is a key characteristic of Large Language Models (LLMs) without Retrieval Augmented Generation (RAG)?
    - [x] They rely on internal knowledge learned during pretraining on a large text corpus.
    - [ ] They always use an external database for generating responses.
    - [ ] They use vector databases exclusively to produce answers.
    - [ ] They cannot generate responses without Fine-Tuning.

      **Explanation**: Large Language Models (LLMs) without Retrieval Augmented Generation (RAG) primarily rely on
      internal knowledge learned during pretraining on a large text corpus. These models are trained on vast amounts of
      text data, which enables them to learn complex patterns, structures, and relationships within language.

2. What differentiates semantic search from traditional keyword search?
    - [ ] It depends on the number of times keywords appear in the content.
    - [x] It involves understanding the intent and context of the search.
    - [ ] It relies solely on matching exact keywords in the content.
    - [ ] It is based on the date and author of the content.

      **Explanation**: Semantic search differs from traditional keyword search in that it involves understanding the
      intent and context of the search query, rather than relying solely on matching exact keywords in the content.

3. How are prompt templates typically designed for language models?
    - [x] As predefined recipes that guide the generation of language model prompts
    - [ ] As complex algorithms that require manual compilation
    - [ ] To be used without any modification or customization
    - [ ] To only work with numerical data instead of textual content

      **Explanation**: Prompt templates for language models are typically designed as predefined recipes that guide the
      generation of prompts. By using predefined templates, developers can ensure consistency and coherence in the
      prompts generated for the language model. These templates may include placeholders or variables representing
      different components of the prompt, such as user queries, context, or response options.

4. What is the LCEL in the context of LangChain chains?
    - [ ] A programming language used to write documentation for LangChain
    - [ ] A legacy method for creating chains in LangChain
    - [ ] An older Python library for building Large Language Models
    - [x] A declarative way to compose chains together using LangChain Expression Language

      **Explanation**: LECL, or LangChain Expression Language, is a declarative way to compose chains together within
      the LangChain framework. It provides a structured and expressive syntax for defining the composition of chains,
      specifying the sequence of components and their interactions in a clear and concise manner.

5. What is the purpose of memory in the LangChain framework?
    - [ ] To act as a static database for storing permanent records
    - [ ] To retrieve user input and provide real-time output only
    - [ ] To perform complex calculations unrelated to user interaction
    - [x] To store various types of data and provide algorithms for summarizing past interactions

      **Explanation**: In the LangChain framework, memory serves as a dynamic repository for retaining and managing
      information throughout the system's operation. It allows the framework to maintain state and context, enabling
      chains to access, reference, and utilize past interactions and information in their decision-making processes.

