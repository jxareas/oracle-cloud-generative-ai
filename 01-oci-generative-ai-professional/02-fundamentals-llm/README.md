<p align="center">
  <img src="./images/large_language_model.png" width="700" height="250" />
</p>

<div align="center">
   <!-- Replace this logo for a custom official logo -->
    <h1 align = "center">
    <b>Fundamentals of Large Language Models</b>
    </h1>
</div>

This module covers a theoretical understanding of what large language models are, what they do and how they work at a 
technical level.

## Table of Contents
- [Introduction to Large Language Models](#introduction-to-large-language-models)
- [LLM Architectures](#llm-architectures)
- [Prompting and Prompt Engineering](#prompting-and-prompt-engineering)
- [Model Training](#model-training)
- [Decoding](#decoding)
- [Hallucinations](#hallucinations)
- [LLM Applications](#llm-applications)

## Introduction to Large Language Models
<!-- Add content explaining what LLMs are, their history, and why they matter -->

## LLM Architectures
<!-- Add content about different LLM architectures such as Transformer, GPT, BERT, etc. -->

## Prompting and Prompt Engineering
<!-- Add content about how prompts are designed, techniques to improve LLM responses -->

## Model Training
<!-- Add content about training datasets, supervised vs. unsupervised learning, fine-tuning -->

## Decoding
<!-- Add content about decoding strategies like greedy, beam search, top-k, nucleus sampling -->

## Hallucinations
<!-- Add content about when and why LLMs generate incorrect or fabricated outputs -->

## LLM Applications
<!-- Add content about practical use cases such as chatbots, summarization, code generation, etc. -->
